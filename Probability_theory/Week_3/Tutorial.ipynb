{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:black\" align=\"center\">Неделя 3</h1>\n",
    "<h1 style=\"color:black\" align=\"center\">Обобщение понятия вероятности</h1>\n",
    "\n",
    "<h1 style=\"color:#008B8B\">Вероятностное пространство в классическом случае</h1>\n",
    "\n",
    "На данный момент уже были рассмотрены две вероятностные схемы: классическая вероятность и схема испытаний Бернулли. Однако современная теория вероятностей намного богаче. Изученные схемы являются весьма ограниченными и необходимо сначала построить их естественное обобщение на случай произвольного конечного вероятностного пространства.\n",
    "\n",
    "Для начала следует напомнить основные положения классической вероятностной схемы и схемы испытаний Бернулли. В обоих схемах присутствует конечное множество всех элементарных исходов $\\Omega$, а событием $A$ называется любое его подмножество $A\\subseteq\\Omega$.\n",
    "\n",
    "В классической вероятностной схеме каждому элементарному исходу из $\\Omega=\\{\\omega_1,\\ldots, \\omega_n\\}$ сопоставляется одинаковая вероятность:\n",
    "\n",
    "$\\large {\\sf P}(\\omega_i):=\\frac{1}{n}$\n",
    "\n",
    "В таком случае вероятность события выражается как отношение числа благоприятных исходов $|A|$ к их общему количеству:\n",
    "\n",
    "$\\large {\\sf P}(A):= \\frac{|A|}{n}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#008B8B\">Вероятностное пространство в схеме Бернулли</h1>\n",
    "\n",
    "В случае схемы испытаний Бернулли множество элементарных исходов состояло из $2^n$ элементарных событий\n",
    "\n",
    "$\\large \\Omega=\\{\\omega_1,\\ldots,\\omega_{2^n}\\}$\n",
    "\n",
    "где $n$ — число испытаний. Это связано с тем, что элементарными событиями в данном случае являются последовательности из нулей и единиц реализаций этих испытаний. Тогда для вероятности элементарного исхода верно соотношение\n",
    "\n",
    "$\\large {\\sf P}(\\omega=(x_1,\\ldots,x_n)) = p^{\\sum\\limits_{i=1}^n x_i} \\cdot q^{n-\\sum\\limits_{i=1}^n x_i}$\n",
    "\n",
    "где $p$ — вероятность успеха в одном испытании, а $q = 1 - p$ — вероятность неудачи.\n",
    "\n",
    "Выражение для вероятности события имеет более сложный вид, поскольку вероятности элементарных исходов могут отличаться:\n",
    "\n",
    "$\\large {\\sf P}(A):= \\sum\\limits_{\\omega\\in A} {\\sf P}(\\omega)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#008B8B\">Конечное вероятностное пространство</h1>\n",
    "\n",
    "Естественное обобщение как классической вероятности, так и схемы Бернулли можно построить следующим образом. Пусть задано произвольное конечное множество объектов:\n",
    "\n",
    "$\\large \\Omega =\\{\\omega_1,\\ldots, \\omega_n\\}$\n",
    "\n",
    "где каждый объект $\\omega_i$  является элементарным исходов, а $\\Omega$ — пространство элементарных исходов. Вероятности элементарных исходов есть некоторые числа $p_i$:\n",
    "\n",
    "$\\large {\\sf P}(\\omega_1) = p_1, \\quad {\\sf P}(\\omega_2)=p_2, \\quad \\ldots, \\quad {\\sf P}(\\omega_n)=p_n$\n",
    "\n",
    "которые должны удовлетворять следующим естественным требованиям:\n",
    "\n",
    "$\\large p_i\\in[0,1], \\qquad p_1+\\ldots+p_n=1$\n",
    "\n",
    "Эти требования выражают условия того, что вероятность определена корректно (чтобы вероятность удовлетворяла свойсвам вероятности)\n",
    "\n",
    "Событием $A$ будет называться любое подмножество пространства элементарных исходов $A\\subseteq \\Omega$. Если элементарный исход принадлежит множеству $A$, то говорят, что он благоприятствует событию $A$. Вероятность ${\\sf P}(A)$ события $A$ по определению полагается равной сумме вероятностей всех элементарных исходов, которые благоприятствуют данному событию:\n",
    "\n",
    "$\\large {\\sf P}(A):= \\sum\\limits_{\\omega\\in A} p_i$\n",
    "\n",
    "В таком случае несложно получить выражения для отрицания $\\bar{A}$ события $A$ и пересечения двух событий $A$ и $B$:\n",
    "\n",
    "$\\large {\\sf P}(\\bar{A}) = 1-{\\sf P}(A), \\qquad {\\sf P}(A\\cup B) = {\\sf P}(A)+{\\sf P}(B)-{\\sf P}(A\\cap B)$\n",
    "\n",
    "Остаются справедливыми и многие оценки, верные в случаях классической схемы или схемы Бернулли, например:\n",
    "\n",
    "$\\large {\\sf P}(A_1 \\cup \\ldots \\cup A_m)\\leq \\sum\\limits_{i=1}^m {\\sf P}(A_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:black\" align=\"center\">Случайные величины</h1>\n",
    "\n",
    "<h1 style=\"color:#008B8B\">Определение случайной величины</h1>\n",
    "\n",
    "**Понятие случайной величины**\n",
    "\n",
    "Понятие случайной величины позволяет более содержательно изучать свойства различных вероятностных пространств. Пусть дано некоторое вероятностное пространство $(\\Omega,{\\sf P})$, то есть задано множество элементарных исходов $\\Omega$, где $P$ означает что заданы вероятности элементарных исходов удовлетворяющие требованиям, которые были разобраны выше.\n",
    "\n",
    "Вещественнозначная функция, определенная на множестве $\\Omega$, называется случайной величиной:\n",
    "\n",
    "$\\large \\xi:\\Omega \\longrightarrow \\mathbb{R}$\n",
    "\n",
    "Эта запись означает, что мы задаём функцию, которая на каждом конкретном элементарном исходе $\\omega$ случайная величина принимает вполне определенное значение $\\xi(\\omega)$. Случайным является элементарный исход, в этом состоит вся случайность, но когда этот элементарный исход реаилзовался, кость упала какой-то стороной кверху, то $\\xi$ принимает конкретное значение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пример.** Пусть $\\Omega=\\{1,2,3,4,5,6\\}$ — пространство исходов при броске игральной кости. Для примера, возьмём следующую функцию $\\xi(\\omega)=\\omega^2$. \n",
    "\n",
    "До бросания кости неизвестно, какое число выпадет, а значит и каково будет значение $\\xi(\\omega)$. Однако после броска функция $\\xi(\\omega)$ примет определенное значение, поскольку реализуется какой-то один элементарный исход.\n",
    "\n",
    "Делаем вывод, что случайная величина это любая функция, которая определена на множестве элементарных исходов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#008B8B\">Понятие случайного графа</h1>\n",
    "\n",
    "Случайный граф является примером вероятностного пространства, на котором позже мы будем демонстрировать описываемые в дальнейшем методы. Случайный граф, вообще говоря, является частным случаем схемы испытаний Бернулли.\n",
    "\n",
    "Множество вершин случайного графа $V_n$ отождествим с множеством натуральных чисел от $1$ до $n$:\n",
    "\n",
    "$\\large V_n=\\{1,2,\\ldots,n\\}$\n",
    "\n",
    "В случайном графе, как видно из определения множества $V_n$, множество и количество вершин фиксировано, а значит случайными буду ребра графа.\n",
    "\n",
    "В полном неориентированном графе на $n$ вершинах без кратных ребер полное количество ребер $e_i$ равно $C_n^2$:\n",
    "\n",
    "$\\large e_1,e_2,\\ldots,e_{C_n^2}$ - Ребра полного графа на $n$ вершинах\n",
    "\n",
    "Теперь пусть зафиксировано число $p\\in [0,1]$, которое принимается равным вероятности каждому отдельному ребру независимо от остальных присутствующих в случайном графе. Фактически имеет место схема Бернулли, где проводятся $C_{n}^2$ испытаний: в случае успеха в каком-то из испытаний ребро, которое соответствует этому испытанию, будет присутствовать в случайном графе, а в случае неудачи — будет отсутствовать. Таким образом, в серии из $C_{n}^2$ испытаний реализуется случайный граф $G=(V_n, E)$, где $V_n$ — фиксированное множество вершин, а $E$ — случайное множество ребер.\n",
    "\n",
    "Каждый граф можно отождествить с элементарным исходом, так как граф фактически является последовательностью из $0$ и $1$, где в схеме испытаний Бернулли пследовательность элементарных исходов из 0 и 1 является элементарным исходом. Следовательно, граф это элементарный исход в нашей схеме. Вероятность того, что реализуется в результате данной схемы какой-то определенный граф равна\n",
    "\n",
    "$\\large {\\sf P}(G=(V_n,E))=p^{|E|}\\cdot q^{C_n^2 - |E|}$ - $p$ в степене числа успехов, а успехов столько, сколько ребер было проведено. Умноженное на $q$ в степени общего количества испытаний минус число успехов. Ну оно и понятн, так как это частный случай схемы испытаний Бернулли.\n",
    "\n",
    "где $|E|$ — число ребер."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На графах очень удобно задавать случайные величины, поэтому имеет смысл рассмотреть несколько примеров.\n",
    "\n",
    "**Пример**. Пусть $\\xi(G):=\\text{число треугольников}$. Например:\n",
    "\n",
    "В случае, когда $n = 4$. $\\xi$ от первого графа равно $0$, так как число треугольников тоже равно $0$.\n",
    "\n",
    "<img src=\"img/3_2.png\" width=\"300\" height=\"260\">\n",
    "\n",
    "Еще раз стоит отметить, что в зависимости от того, какой элементарный исход реализуется, $\\xi$ может принимать то или иное конкретное значение. Случайная величина называется случайной только из-за того, что её аргумент — объект из вероятностного пространства. После того, как элементарный исход реализовался, случайная величина принимает конкретное значение. Другими словами, $\\xi$ возвращет конкретное не случайное значение, случайной она называется из-за того, что объект который подставляется в $\\xi$ является случайным, так как нам неизвестен результат до резализации этого объекта."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#008B8B\">Распределение случайной величины</h1>\n",
    "\n",
    "Запись вида $\\xi:\\Omega$ означает следующее - задана случайная величина $\\xi$ на пространстве элементарных событий $\\Omega$\n",
    "\n",
    "Пусть задана случайная величина $\\xi:\\Omega \\longrightarrow \\{y_1,\\ldots,y_k\\}$ на пространстве элементарных событий $\\Omega=\\{\\omega_1,\\ldots,\\omega_n\\}$. Что значит случайная величина задана? Это значит, что можно описать все различные значения, которые $\\xi$ принимает на элементарных исходах, так как элементарных исходов конечное число, то и различных значений, которые $\\xi$ принимает на элементарных исходах тоже конечное число и мы их обозначим как $\\{y_1,\\ldots,y_k\\}$, ну а $\\Omega$ состоит из элементархы исходов, которых $n$ штук. Другими словами, это значит, что заданы значения случайной величины для всех элементарных исходов.\n",
    "\n",
    "При этом, $k$ может не совпадать с $n$, хорошим примером служит количество треугольников на случайном графе.\n",
    "\n",
    "**Распределние случайной величины:**\n",
    "\n",
    "В теории вероятностей часто бывает нужно знать не такую функциональную зависимость, то как устроена функция, а распределение случайной величины. Распределение случайной величины — это центральное понятие в теории вероятностей. \n",
    "\n",
    "Нас интересуют вероятности с которой $\\xi$ принимает конкртеное свое значение $y_i$, все это можно записать как ${\\sf P}(\\xi=y_i)$. Подробнее, имеется вероятность события, состоящего из всех $\\omega_j$, на которых $\\xi(\\omega_j)$ принимает значение $y_i$ всё это можно записать как ${\\sf P}(\\{\\omega_j : \\xi(\\omega_j)=y_i\\})$\n",
    "\n",
    "\n",
    "Говорят, что распределение известно, если известны все вероятности того, что $\\xi$ принимает какое-то возможное значение $y_i$:\n",
    "\n",
    "$\\large {\\sf P}(\\xi=y_i)= {\\sf P}(\\{\\omega_j : \\xi(\\omega_j)=y_i\\})$\n",
    "\n",
    "Распределение может быть как задано по условию задачи, так и являться искомым в задаче.\n",
    "\n",
    "**Пример.** Пусть $\\xi$ на пространстве графов — случайная величина, равная числу треугольников в графе. \n",
    "\n",
    "$\\large {\\sf P}(\\xi=k) = ?$\n",
    "\n",
    "Какое значение $k$ может принимать случайная величина, где $k$ представляет собой число треугольников в случайном графе на $n$ вершинах. Если граф был построен на $n$ вершинах, то максимальное число треугольников $C_n^3$ будет наблюдаться в случае полного графа. Значит, $k$ изменяется от $0$ до $C_n^3$:\n",
    "\n",
    "$\\large k=0,1,\\ldots,C_{n}^3$\n",
    "\n",
    "Тогда говорят, что известно распределение случайной величины $\\xi$, если известны следующие вероятности:\n",
    "\n",
    "$\\large {\\sf P}(\\xi=k), \\quad k=0,1,\\ldots,C_{n}^3$\n",
    "\n",
    "Вычислить точно распределение функции $\\xi$ с помощью численного расчета очень сложно, поэтому очень важны асимптотические методы оценки функций распределений случайных величин."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:black\" align=\"center\">Математическое ожидание случайной величины</h1>\n",
    "\n",
    "<h1 style=\"color:#008B8B\">Определение математического ожидания случайной величины</h1>\n",
    "\n",
    "### Математическое ожидание:\n",
    "\n",
    "Математическое ожидание случайной величины $\\xi$ принято обозначать двумя различными способами. Обозначение $E\\xi$ восходит к английскому выражению \"expected value\", а $M\\xi$ — \"mean value\".\n",
    "\n",
    "Математическое ожидание случайной величины $\\xi$, определенной на конечном вероятностном пространстве, определяется согласно следующему выражению:\n",
    "\n",
    "$\\large M\\xi= \\sum\\limits_{\\omega\\in\\Omega} \\xi(\\omega)\\cdot {\\sf P}(\\omega)$\n",
    "\n",
    "В случае классической вероятностной схемы математическое ожидание соответствует среднему арифметическому последовательности из значений случайной величины. \n",
    "\n",
    "Почему математическое ожидание является средним значением? Если мы работаем с классической вероятностью, то веротяность $\\omega = \\frac{1}{n}$. Тогда, после всей суммы $\\omega$ по пространству элементарных исходов мы получим среднее арифметическое значение случайной величины.\n",
    "\n",
    "Вообще говоря, в любом случае математическое ожидание — это некое среднее значение (своего рода центр масс как в физике), так как  $\\sum\\limits_{\\omega\\in\\Omega}{\\sf P}(\\omega)=1$. Важно, что математическое ожидание может не принадлежать множеству возможных значений случайной величины. Это просто середина распределения, следовательно, зная математическое ожидание, можно что-то сказать о нашем распределении."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Другая форма записи математического ожидания\n",
    "\n",
    "Поскольку $\\xi$ на пространстве элементарных исходов принимает $k$ различных значений ($\\xi:\\Omega \\longrightarrow \\{y_1,\\ldots,y_k\\}$), тогда для разных элементарных исходов $\\omega$ из множества $\\Omega$ (пространства элементарных исходов), $\\xi(\\omega)$ может равнятся одному и тому же числу. Например, $y_1$ может приниматься на нескольких элементарных исходах $\\xi(\\omega)$.\n",
    "\n",
    "Поскольку несколько элементарных исходов могут давать одно и то же значение случайной величины, это определение можно переписать, сгруппировав такие элементарные исходы:\n",
    "\n",
    "Сначала собираем все $\\xi(\\omega)$, которые равняются $y_1$, это можно сделать следующим образом:\n",
    "\n",
    "$\\large y_1\\left(\\sum\\limits_{\\omega:\\xi(\\omega)=y_1}P(\\omega)\\right)$\n",
    "\n",
    "Запишем для всех $y_i$:\n",
    "\n",
    "$\\large M\\xi=\\sum\\limits_{\\omega\\in\\Omega}\\xi(\\omega)\\cdot P(\\omega)=y_1\\left(\\sum\\limits_{\\omega:\\xi(\\omega)=y_1}P(\\omega)\\right)+y_2\\left(\\sum\\limits_{\\omega:\\xi(\\omega)=y_2}P(\\omega)\\right)+\\ldots+y_k\\left(\\sum\\limits_{\\omega:\\xi(\\omega)=y_k}P(\\omega)\\right) =$\n",
    "\n",
    "Ну как у нас определялась вероятность события? Вероятность события – это сумма по всем элементарным исходам, которые этому событию благоприятствуют, вероятностей этих элементарных исходов. То есть, конечно же, написано так:\n",
    "\n",
    "$\\large = y_1 P(\\xi=y_1)+y_2 P(\\xi=y_2)+\\ldots +y_k P(\\xi=y_k)=\\sum\\limits_{j=1}^k y_j P(\\xi=y_j)$ - Суммируем различные значения $y_i$, которые принимает случайная величина и каждое значение умножаем на вероятность того, что это значение принимает случайная величина.\n",
    "\n",
    "Последняя формула является естественным проявлением того факта, что математическое ожидание можно вычислить исходя из знания распределения случайной величины. Другими словами, если изначально известны вероятности с которыми случайная величина принимает свое конкретное значение $P(\\xi=y_j)$, тогда математическое ожидание можно посчитать.\n",
    "\n",
    "**Замечание.** Однако часто бывает наоборот: математическое ожидание считается легче, чем распределение, а знание математического ожидания дает возможность получить некоторые важные свойства этого распределения, не вычисляя его."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#008B8B\">Свойство линейности математического ожидания, примеры</h1>\n",
    "\n",
    "Математическое ожидание обладает свойством линейности: пусть $\\xi_{1},\\xi_{2}$  — две произвольные случайные величины на конечном вероятностном пространстве, а $c_{1},c_{2}$ — произвольные вещественные числа, тогда\n",
    "\n",
    "$\\large M(c_1\\xi_1 +c_2\\xi_2)= c_1 M\\xi_1 + c_2 M\\xi_2$\n",
    "\n",
    "Это свойство непосредственно следует из определения математического ожидания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример 1.\n",
    "\n",
    "Найти математическое ожидание случайной величины $\\xi$, где $\\xi$ равна числу треугольников в случайном графе. Множество значений, которые принимает число треугольников в случайном графе — это множество чисел от $0$ до $C_n^3$. Ну тогда, естественно, надо каждое из этих значений умножить на вероятность того, что $\\xi = k$ и просуммировать пока от нуля до $C_n^3$: \n",
    "\n",
    "$\\large M\\xi=\\sum\\limits_{k=0}^{C_n^3} k\\cdot {\\sf P}(\\xi=k)$\n",
    "\n",
    "Чтобы решить данную задачу, необходимо обойти вычисление величины ${\\sf P}(\\xi=k)$ с помощью свойства линейности математического ожидания. Действительно:\n",
    "\n",
    "На вход случайной величины поступает случайный граф $\\xi(G)$. И как на посчитать количество треугольников в графе? Самое простое, что можно сделать - это перебрать всевозможные тройки вершин, и для каждой тройки посмотреть, вот в этом конкретном графе, эта тройка вершин образует треугольник или нет? Ну если образует, добавить к счетчику $1$, если не образует, тогда ничего не добавлять. То есть, запись примет следующий вид:\n",
    "\n",
    "$\\large \\xi(G) = \\xi_1(G)+\\ldots+\\xi_{c_n^3}(G)$,\n",
    "\n",
    "где $\\xi_i(G)$ — случайная величина, которая равна $1$, если треугольник с номером $i$ принадлежит графу $G$. Другими словами, если $i$ тройка вершин образует треугольник в графе $G$, тогда $1$. Иначе, случайная величина равна нулю в иных случаях. Такие случайные величины называются индикаторами и записываются ещё в следующем виде:\n",
    "\n",
    "$\\large \\begin{equation*}\n",
    "\\xi_i(G) = \n",
    " \\begin{cases}\n",
    "   1, & \\text{если $i$ тройка вершин образует треугольник в графе $G$}\\\\\n",
    "   0, &\\text{иначе}\n",
    " \\end{cases}\n",
    "\\end{equation*}$\n",
    "\n",
    "Дальше, пользуемся свойством линейности и получаем, что математическое ожидание кси равно:\n",
    "\n",
    "$\\large M\\xi = M\\xi_1 +\\ldots+M\\xi_{c_n^3}$\n",
    "\n",
    "А математическое ожидание каждой из случайных величин $\\xi_i$ можно посчитать по следующей формуле:\n",
    "\n",
    "$\\large M\\xi_i= {\\sf P}(\\xi_i = 1)= p^3$\n",
    "\n",
    "Ну в самом деле, какие значения  $\\xi_i$ принимает? Это $1$ и $0$ То есть надо $1$ умножить на вероятность $1$ и прибавить $0$, умноженный на вероятность $0$. Так как ноль не вносит вклад, мы считаем, что математическое ожидание $\\xi_i$ равно вероятности того, что $\\xi_i = 1$. С какой вероятностью эта конкретная тройка вершин образует треугольник в случайном графе? Но каждое ребро возникает с вероятностью $p$, независимо от остальных. Значит все три вероятности $p$ необходимо перемножить и мы получаем $p^3$.\n",
    "\n",
    "У нас получилось, что каждая из вот этих слагаемых есть $p$ в кубе. Слагаемых $C_n^3$, ну в итоге получаем ответ $C_n^3$ на $p$ в кубе:\n",
    "\n",
    "$\\large M\\xi = M\\xi_1 +\\ldots+M\\xi_{c_n^3} = C_n^3 p^3$\n",
    "\n",
    "Воспользовавшись перегруппировкой слагаемых с помощью линейности можно найти ответ  практически в уме. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример 2.\n",
    "\n",
    "В схеме испытаний Бернулли рассматривается случайная величина $\\mu_n$, которая равна количеству успехов во всех испытаниях, где каждый успех случается с вероятностью $p$. \n",
    "\n",
    "Чему равняется $\\mu_n$? Ну понятно, что это случайная величина. Когда мы реализовали схему испытаний Бернулли, число успехов — это число раз, когда возникала $1$, то есть, можно сказать, что $\\mu_n$ — это сумма $x_i$ по $i$ от $1$ до $n$:\n",
    "\n",
    "$\\large \\mu_n = \\sum\\limits_{i=1}^n x_i$\n",
    "\n",
    "Но $x_i$  — тоже случайная величина (индекаторная), которая равна $1$, если в $i$-ом испытании был успех, где успех происходи с вероятностью $p$, а если произошла неудача, то случайная величина равна нулю, с вероятностью $q$ соответственно:\n",
    "\n",
    "$\\large \\begin{equation*}\n",
    "\\mu_i = \n",
    " \\begin{cases}\n",
    "   1, & \\text{с вероятностью $p$}\\\\\n",
    "   0, &\\text{с вероятностью $q$}\n",
    " \\end{cases}\n",
    "\\end{equation*}$\n",
    "\n",
    "В прошлом примере мы использовали для обозначения случайной величины $\\xi_i$, можно запись выше записать в следующем виде:\n",
    "\n",
    "$\\large \\mu_n = \\sum\\limits_{i=1}^n \\xi_i$\n",
    "\n",
    "Тогда несложно можно получить выражение для математического ожидания (среднее число успехов в схеме испытаний Бернулли):\n",
    "\n",
    "$\\large M{\\mu_n} =np$\n",
    "\n",
    "Это выражение можно понять следующим образом, если, $p = \\frac{1}{2}$, тогда среднее число успехов в схеме испытаний Бернулли должно быть $n$ пополам.\n",
    "\n",
    "Линейность математического ожидания является исключительно полезным свойством, которое, при всей своей тривиальности, позволяет рассчитывать математическое ожидание даже тогда, когда мы не знаем распределение случайной величины."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#008B8B\">Неравенство Маркова</h1>\n",
    "\n",
    "**Теорема**. Пусть случайная величина $\\xi$ принимает только неотрицательные значения. Пусть дано положительное число $a>0$. Тогда вероятность ${\\sf P}(\\xi\\geq a)$ того, что случайная величина $\\xi$ не меньше $a$, удовлетворяет неравенству:\n",
    "\n",
    "$\\large {\\sf P}(\\xi\\geq a)\\leq \\frac{M\\xi}{a}.$\n",
    "\n",
    "**Док-во.** Согласно определению математического ожидания: Где после, мы сумму разобъем на две части, где в одной части будут находиться $j$ для которых $y_j \\ge a$ и прибавляем оставшуюся часть:\n",
    "\n",
    "$\\large M\\xi = \\sum\\limits_{j=1}^k y_j {\\sf P}(\\xi=y_j) = \\sum\\limits_{j:y_j\\geq a} y_j {\\sf P}(\\xi=y_j)+ \\sum\\limits_{j:y_j< a} y_j {\\sf P}(\\xi=y_j).$\n",
    "\n",
    "Для второго слогаемого заметим, что $y_j \\ge 0$ - это неотрицательное число, так как по условию $\\xi$ принимает только неотрицательные значения. Вероятность тоже больше нуля ${\\sf P}(\\xi=y_j) \\ge 0$. Значит и вся сумма тоже неотрицательная. Оценим второе слагаемое в последнем выражении можно оценить снизу нулем.\n",
    "\n",
    "$\\large M\\xi \\geq \\sum\\limits_{j:y_j\\geq a} y_j {\\sf P}(\\xi=y_j)$\n",
    "\n",
    "Так как все $y_j\\geq a$ по определению суммы, тогда выносим $a$ за знак суммирования, так как оно общее для всех и запишем сумму:\n",
    "\n",
    "$\\large \\geq a\\sum\\limits_{j:y_j\\geq a} {\\sf P}(\\xi=y_j) = a{\\sf P}(\\xi \\geq a).$\n",
    "\n",
    "Понятно, что $j:y_j\\geq a$ мы взяли событие состоящие в том, что $P(\\xi \\ge a)$ и разбил его на непересекающиеся кусочки и посмотрели на каждое значение, которое $\\ge a$ и посчитали его вероятность. Если $P(\\xi \\ge a)$ есть вероятность собыитя $A$, которое нас интересует, тогда под суммой стоят события $A_j$, следовательно, событие $A$ является дизьюнктным объединением $A = A_1 \\sqcup A_2, \\ldots$, поэтому по свойству вероятностей, интересующая нас вероятность это сумма вероятностей, как и написано в формуле.\n",
    "\n",
    "Читаем справа-налево. Откуда следует требуемое выражение:\n",
    "\n",
    "$\\large {\\sf P}(\\xi\\geq a) \\leq \\frac{M\\xi}{a}.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Применение неравенства Маркова в задаче о пороговой вероятности существования треугольника\n",
    "\n",
    "**Теорема.** Пусть число вершин $n$ случайного графа растет к бесконечности и пусть вероятность проведения ребра случайного графа $p=p(n)$ такова, что $np(n) \\to 0$ при $n\\to\\infty$. То есть, вероятность отдельно взятого ребра бесконечно мала в сравнении с $\\frac{1}{n}$. Тогда с асимптотической вероятностью $1$ в случайном графе нет треугольников: ${\\sf P}(\\xi=0) \\to 1$ при $n\\to \\infty$.\n",
    "\n",
    "**Док-во.** Согласно неравенству Маркова:\n",
    "\n",
    "${\\sf P}( \\xi = 0 )= 1-{\\sf P}(\\xi\\geq 1) \\geq 1-M\\xi=1-C_{n}^3 p^3.$\n",
    "\n",
    "Так как  $np(n) \\to 0$, то  $C_{n}^3 p^3 = \\frac{n(n-1)(n-2)}{6}p^3 \\sim \\frac{n^3 p^3}{6} \\to 0$. \n",
    "\n",
    "Откуда следует требуемое утверждение: ${\\sf P}(\\xi=0)\\to 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#008B8B\">Дисперсия случайной величины</h1>\n",
    "\n",
    "Дисперсия $D \\xi$ случайной величины $\\xi$ определяется следующим образом: \n",
    "\n",
    "$D \\xi:= M(\\xi-M\\xi)^2.$\n",
    "\n",
    "**Что здесь подразумевается под выражением $(\\xi-M\\xi)^2$?**\n",
    "\n",
    "Так как $M\\xi$ - это число, то $(\\xi-M\\xi)^2$ - это функция, которая каждому $\\omega$ ставит в соответствие число $(\\xi(\\omega)-M\\xi)^2$.\n",
    "\n",
    "\n",
    "**Продолжаем рассуждения:**\n",
    "\n",
    "Дисперсия позволяет оценить разброс случайной величины относительно её среднего значения, то есть найти среднеквадратичное отклонение $\\xi$ от своего среднего значения.\n",
    "\n",
    "**Замечание.** Более простое выражение $M(\\xi-M\\xi)$ не подходит для оценки разброса распределения вокруг среднего значения, так как: \n",
    "\n",
    "$M(\\xi-M\\xi) = M(\\xi) - M(M\\xi) = M(\\xi) - M(\\xi) = 0.$ - распишем по линейности математического ожидания. После получаем, что $M(M\\xi) = M(\\xi)$, так как $M\\xi$ - это константа и если от нее взять математическое ожидание, тогда по определению мы получим эту же константу.\n",
    "\n",
    "Выражение для вычисления дисперсии можно преобразовать с помощью свойства линейности:\n",
    "\n",
    "$\\large M(\\xi-M\\xi)^2 = M(\\xi^2 -2\\xi \\cdot M\\xi + (M\\xi)^2) =$\n",
    "\n",
    "Заметим, что $M\\xi$ - это тоже константа и $(M\\xi)^2$ константа, математическое ожидание от $(M\\xi)^2$ равно $(M\\xi)^2$:\n",
    "\n",
    "$\\large = M\\xi^2 -2M\\xi\\cdot M\\xi + (M\\xi)^2 = M\\xi^2 - (M\\xi)^2.$ \n",
    "\n",
    "То есть \n",
    "\n",
    "$\\large D \\xi= M\\xi^2 - (M\\xi)^2.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#008B8B\">Неравенство Чебышёва</h1>\n",
    "\n",
    "Пусть $\\eta$ — любая случайная величина. Пусть  $b>0$, тогда выполняется неравенство \n",
    "\n",
    "$\\large {\\sf P}\\left(|\\eta-M\\eta|\\geq b\\right) \\leq \\frac{D\\eta}{b^2}.$ - Вероятность с которой ета укланяется от своего среднего значения не меньше чем на заданную величину $b$ - не превосходит дисперсии деленное на эту величу $b^2$ в квадрате.\n",
    "\n",
    "Таким способом можно измерять вероятность уклонения случайной величины от своего среднего значения.\n",
    "\n",
    "**Док-во.** Согласно неравенству Маркова предположим при $\\xi = (\\eta-M\\eta)^2 \\geq 0$ и $a=b^2$:\n",
    "\n",
    "$\\large {\\sf P}(\\xi\\geq a)\\leq \\frac{M\\xi}{a} \\quad \\implies \\quad {\\sf P}\\left((\\eta-M\\eta)^2 \\geq b^2\\right)\\leq \\frac{M(\\eta-M\\eta)^2}{b^2}=\\frac{D\\eta}{b^2}.$\n",
    "\n",
    "Здесь было использовано определение дисперсии. Таким образом, мы получили, что вероятность такого уклонения оценивается сверху следующим отношением:\n",
    "\n",
    "$\\large {\\sf P}(\\xi\\geq a)\\leq \\frac{D\\eta}{b^2}.$\n",
    "\n",
    "Неравенство доказано."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Асимптотическое число треугольников в случайном графе\n",
    "\n",
    "**Теорема.** Пусть $n$ растет и $p=p(n)$, причем  $np(n)\\to +\\infty$. Тогда ${\\sf P}(\\xi\\geq 1) \\to 1$, то есть асимптотически почти наверное в случайном графе есть треугольники.\n",
    "\n",
    "**Док-во.** Для вероятности ${\\sf P}(\\xi\\geq 1)$ можно произвести следующие оценки, используя неравенство Чебышёва:\n",
    "\n",
    "${\\sf P}(\\xi\\geq 1) = 1-{\\sf P}(\\xi\\leq 0) = 1-{\\sf P}(-\\xi\\geq 0) = 1-{\\sf P}(M\\xi-\\xi\\geq M\\xi) \\geq 1-{\\sf P}(|\\xi-M\\xi|\\geq M\\xi) \\geq 1- \\frac{D \\xi}{(M\\xi)^2}.$\n",
    "\n",
    "Для дисперсии можно привести следующие выражения: \n",
    "$D\\xi=M\\xi^2 - (M\\xi)^2, \\qquad M\\xi^2 = M(\\xi_1 + \\ldots + \\xi_{C_n^3})^2 = M\\left(\\xi_{1}^2+\\ldots+\\xi_{C_n^3}^2 + \\sum\\limits_{i\\neq j}\\xi_i\\xi_j\\right),$ где $\\xi_i = \\xi_i^2$: \n",
    "\n",
    "\n",
    "$i$-ая тройка вершин образует треугольник \n",
    "\n",
    "### Система \n",
    "\n",
    "Так как $\\xi_i \\xi_j = 1$ тогда и только тогда, когда обе тройки $i$ и $j$ образуют треугольник:\n",
    "\n",
    "$M\\xi^2 = C_n^3 p^3 + \\sum\\limits_{i\\neq j}M(\\xi_i \\xi_j) = C_n^3 p^3 + \\sum\\limits_{i\\neq j} P(\\text{тройки i и j образуют треугольники}).$\n",
    "\n",
    "Такая ситуация может возникнуть в одном из трех случаев: \n",
    "\n",
    "<img src=\"img/3_3.png\" width=\"300\" height=\"260\">\n",
    "\n",
    "<img src=\"img/3_4.png\" width=\"300\" height=\"260\">\n",
    "\n",
    "<img src=\"img/3_5.png\" width=\"300\" height=\"260\">\n",
    "\n",
    "В первом и втором случаях нужные $6$ ребер присутствуют в случайном графе с вероятностью $p^6$, в третьем случае таких ребер $5$ и вероятность будет $p^5$. Тогда:\n",
    "\n",
    "$M(\\xi_i \\xi_j) =(C_n^3 C_{n-3}^3 + C_n^3 3 C_{n-3}^2)p^6 + C_n^3 3 (n-3)p^5.$\n",
    " \n",
    "$\\frac{D \\xi}{(M\\xi)^2}=\\frac{1}{M\\xi} + \\frac{(C_n^3 \\cdot C_{n-3}^3 + C_n^3 \\cdot 3 \\cdot C_{n-3}^2)p^6}{(C_n^3 p^3)^2} +\\frac{3C_n^3 (n-3)p^5}{(C_n^3 p^3)^2} - 1$\n",
    "\n",
    "Так как\n",
    "\n",
    "$M\\xi= C_n^3 p^3\\sim \\frac{n^3 p^3}{6} \\to \\infty \\text{ при } np(n)\\to \\infty,$\n",
    "\n",
    "можно получить следующие асимптотические оценки\n",
    "\n",
    "$\\frac{C_n^3 C_{n-3}^3 p^6}{(C_n^3)^2 p^6} = \\frac{C_{n-3}^3}{C_n^3} \\sim 1, \\qquad \\frac{3C_n^3 C_{n-3}^2 p^6}{(C_n^3)^2 p^6} \\to 0.$\n",
    " \n",
    "$\\frac{3C_n^3 (n-3)p^5}{(C_n^3)^2 p^6} \\sim \\frac{3n \\cdot 6}{n^3 p} = \\frac{18}{n^2 p} \\to 0.$\n",
    "\n",
    "В итоге $\\frac{D\\xi}{(M\\xi)^2}\\to 0$, что и требовалось доказать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
