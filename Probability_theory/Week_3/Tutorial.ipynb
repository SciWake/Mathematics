{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:black\" align=\"center\">Неделя 3</h1>\n",
    "<h1 style=\"color:black\" align=\"center\">Обобщение понятия вероятности</h1>\n",
    "\n",
    "<h1 style=\"color:#008B8B\">Вероятностное пространство в классическом случае</h1>\n",
    "\n",
    "На данный момент уже были рассмотрены две вероятностные схемы: классическая вероятность и схема испытаний Бернулли. Однако современная теория вероятностей намного богаче. Изученные схемы являются весьма ограниченными и необходимо сначала построить их естественное обобщение на случай произвольного конечного вероятностного пространства.\n",
    "\n",
    "Для начала следует напомнить основные положения классической вероятностной схемы и схемы испытаний Бернулли. В обоих схемах присутствует конечное множество всех элементарных исходов $\\Omega$, а событием $A$ называется любое его подмножество $A\\subseteq\\Omega$.\n",
    "\n",
    "В классической вероятностной схеме каждому элементарному исходу из $\\Omega=\\{\\omega_1,\\ldots, \\omega_n\\}$ сопоставляется одинаковая вероятность:\n",
    "\n",
    "$\\large {\\sf P}(\\omega_i):=\\frac{1}{n}$\n",
    "\n",
    "В таком случае вероятность события выражается как отношение числа благоприятных исходов $|A|$ к их общему количеству:\n",
    "\n",
    "$\\large {\\sf P}(A):= \\frac{|A|}{n}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#008B8B\">Вероятностное пространство в схеме Бернулли</h1>\n",
    "\n",
    "В случае схемы испытаний Бернулли множество элементарных исходов состояло из $2^n$ элементарных событий\n",
    "\n",
    "$\\large \\Omega=\\{\\omega_1,\\ldots,\\omega_{2^n}\\}$\n",
    "\n",
    "где $n$ — число испытаний. Это связано с тем, что элементарными событиями в данном случае являются последовательности из нулей и единиц реализаций этих испытаний. Тогда для вероятности элементарного исхода верно соотношение\n",
    "\n",
    "$\\large {\\sf P}(\\omega=(x_1,\\ldots,x_n)) = p^{\\sum\\limits_{i=1}^n x_i} \\cdot q^{n-\\sum\\limits_{i=1}^n x_i}$\n",
    "\n",
    "где $p$ — вероятность успеха в одном испытании, а $q = 1 - p$ — вероятность неудачи.\n",
    "\n",
    "Выражение для вероятности события имеет более сложный вид, поскольку вероятности элементарных исходов могут отличаться:\n",
    "\n",
    "$\\large {\\sf P}(A):= \\sum\\limits_{\\omega\\in A} {\\sf P}(\\omega)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#008B8B\">Конечное вероятностное пространство</h1>\n",
    "\n",
    "Естественное обобщение как классической вероятности, так и схемы Бернулли можно построить следующим образом. Пусть задано произвольное конечное множество объектов:\n",
    "\n",
    "$\\large \\Omega =\\{\\omega_1,\\ldots, \\omega_n\\}$\n",
    "\n",
    "где каждый объект $\\omega_i$  является элементарным исходов, а $\\Omega$ — пространство элементарных исходов. Вероятности элементарных исходов есть некоторые числа $p_i$:\n",
    "\n",
    "$\\large {\\sf P}(\\omega_1) = p_1, \\quad {\\sf P}(\\omega_2)=p_2, \\ldots, \\quad {\\sf P}(\\omega_n)=p_n$\n",
    "\n",
    "которые должны удовлетворять следующим естественным требованиям:\n",
    "\n",
    "$\\large p_i\\in(0,1], \\qquad p_1+\\ldots+p_n=1$\n",
    "\n",
    "Эти требования выражают условия того, что вероятность определена корректно (чтобы вероятность удовлетворяла свойсвам вероятности)\n",
    "\n",
    "Событием $A$ будет называться любое подмножество пространства элементарных исходов $A\\subseteq \\Omega$. Если элементарный исход принадлежит множеству $A$, то говорят, что он благоприятствует событию $A$. Вероятность ${\\sf P}(A)$ события $A$ по определению полагается равной сумме вероятностей всех элементарных исходов, которые благоприятствуют данному событию:\n",
    "\n",
    "$\\large {\\sf P}(A):= \\sum\\limits_{\\omega\\in A} p_i$\n",
    "\n",
    "В таком случае несложно получить выражения для отрицания $\\bar{A}$ события $A$ и пересечения двух событий $A$ и $B$:\n",
    "\n",
    "$\\large {\\sf P}(\\bar{A}) = 1-{\\sf P}(A), \\qquad {\\sf P}(A\\cup B) = {\\sf P}(A)+{\\sf P}(B)-{\\sf P}(A\\cap B)$\n",
    "\n",
    "Остаются справедливыми и многие оценки, верные в случаях классической схемы или схемы Бернулли, например:\n",
    "\n",
    "$\\large {\\sf P}(A_1 \\cup \\ldots \\cup A_m)\\leq \\sum\\limits_{i=1}^m {\\sf P}(A_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:black\" align=\"center\">Случайные величины</h1>\n",
    "\n",
    "<h1 style=\"color:#008B8B\">Определение случайной величины</h1>\n",
    "\n",
    "**Понятие случайной величины**\n",
    "\n",
    "Понятие случайной величины позволяет более содержательно изучать свойства различных вероятностных пространств. Пусть дано некоторое вероятностное пространство $(\\Omega,{\\sf P})$, то есть задано множество элементарных исходов $\\Omega$, где $P$ означает что заданы вероятности элементарных исходов удовлетворяющие требованиям, которые были разобраны выше.\n",
    "\n",
    "Вещественнозначная функция, определенная на множестве $\\Omega$, называется случайной величиной:\n",
    "\n",
    "$\\large \\xi:\\Omega \\longrightarrow \\mathbb{R}$\n",
    "\n",
    "Эта запись означает, что мы задаём функцию, которая на каждом конкретном элементарном исходе $\\omega$ случайная величина принимает вполне определенное значение $\\xi(\\omega)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пример.** Пусть $\\Omega=\\{1,2,3,4,5,6\\}$ — пространство исходов при броске игральной кости. Для примера, возьмём следующую функцию $\\xi(\\omega)=\\omega^2$. \n",
    "\n",
    "До бросания кости неизвестно, какое число выпадет, а значит и каково будет значение $\\xi(\\omega)$. Однако после броска функция $\\xi(\\omega)$ примет определенное значение, поскольку реализуется какой-то один элементарный исход.\n",
    "\n",
    "Делаем вывод, что случайная величина это любая функция, которая определена на множестве элементарных исходов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#008B8B\">Понятие случайного графа</h1>\n",
    "\n",
    "Случайный граф является примером вероятностного пространства, на котором позже мы будем демонстрировать описываемые в дальнейшем методы. Случайный граф, вообще говоря, является частным случаем схемы испытаний Бернулли.\n",
    "\n",
    "Множество вершин случайного графа $V_n$ отождествим с множеством натуральных чисел от $1$ до $n$:\n",
    "\n",
    "$\\large V_n=\\{1,2,\\ldots,n\\}$\n",
    "\n",
    "В случайном графе, как видно из определения множества $V_n$, множество и количество вершин фиксировано, а значит случайными буду ребра графа.\n",
    "\n",
    "В полном неориентированном графе на $n$ вершинах без кратных ребер полное количество ребер $e_i$ равно $C_n^2$:\n",
    "\n",
    "$\\large e_1,e_2,\\ldots,e_{C_n^2}$ - Ребра полного графа на $n$ вершинах\n",
    "\n",
    "Теперь пусть зафиксировано число $p\\in [0,1]$, которое принимается равным вероятности каждому отдельному ребру независимо от остальных присутствовать в случайном графе. Фактически имеет место схема Бернулли, где проводятся $C_{n}^2$ испытаний: в случае успеха в каком-то из испытаний ребро, которое соответствует этому испытанию, будет присутствовать в случайном графе, а в случае неудачи — будет отсутствовать. Таким образом, в серии из $C_{n}^2$ испытаний реализуется случайный граф $G=(V_n, E)$, где $V_n$ — множество вершин, а $E$ — множество ребер.\n",
    "\n",
    "Каждый граф можно отождествить с элементарным исходом, так как граф фактически является последовательностью из $0$ и $1$. Вероятность того, что реализуется в результате данной схемы какой-то определенный граф равна\n",
    "\n",
    "$\\large {\\sf P}(G=(V_n,E))=p^{|E|}\\cdot q^{C_n^2 - |E|}$\n",
    "\n",
    "где $|E|$ — число ребер."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На графах очень удобно задавать случайные величины, поэтому имеет смысл рассмотреть несколько примеров.\n",
    "\n",
    "**Пример**. Пусть $\\xi(G):=\\text{число треугольников}$. Например:\n",
    "\n",
    "В случае, когда $n = 4$. $\\xi$ от первого графа равно $0$, так как число треугольников тоже равно $0$.\n",
    "\n",
    "<img src=\"img/3_2.png\" width=\"300\" height=\"260\">\n",
    "\n",
    "Еще раз стоит отметить, что в зависимости от того, какой элементарный исход реализуется, $\\xi$ может принимать то или иное конкретное значение. Случайная величина называется случайной только из-за того, что её аргумент — объект из вероятностного пространства. После того, как элементарный исход реализовался, случайная величина принимает конкретное значение. Другими словами, $\\xi$ возвращет конкретное не случайное значение, случайной она называется из-за того, что объект который подставляется в $\\xi$ является случайным, так как нам неизвестен результат до резализации этого объекта."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#008B8B\">Распределение случайной величины</h1>\n",
    "\n",
    "Запись вида $\\xi:\\Omega$ означает следующее - задана случайная величина $\\xi$ на пространстве элементарных событий $\\Omega$\n",
    "\n",
    "Пусть задана случайная величина $\\xi:\\Omega \\longrightarrow \\{y_1,\\ldots,y_k\\}$ на пространстве элементарных событий $\\Omega=\\{\\omega_1,\\ldots,\\omega_n\\}$. Что значит случайная величина задана? Это значит, что можно описать все различные значения, которые $\\xi$ принимает на элементарных исходах, так как элементарных исходов конечное число, то и различных значений, которые $\\xi$ принимает на элементарных исходах тоже конечное число. Другими словами, это значит, что заданы значения случайной величины для всех элементарных исходов.\n",
    "\n",
    "При этом, $k$ может не совпадать с $n$, хорошим примером служит количество треугольников на случайном графе.\n",
    "\n",
    "**Распределние случайной величины:**\n",
    "\n",
    "В теории вероятностей часто бывает нужно знать не такую функциональную зависимость, то как устроена функция, а распределение случайной величины. Распределение случайной величины — это центральное понятие в теории вероятностей. \n",
    "\n",
    "Нас интересуют вероятности с которой $\\xi$ принимает значение $y_i$, все это можно записать как ${\\sf P}(\\xi=y_i)$. Подробнее, имеется вероятность события, состоящего из всех $\\omega_j$, на которых $\\xi(\\omega_j)$ принимает значение $y_i$ всё это можно записать как ${\\sf P}(\\{\\omega_j : \\xi(\\omega_j)=y_i\\})$\n",
    "\n",
    "\n",
    "Говорят, что распределение известно, если известны все вероятности того, что $\\xi$ принимает какое-то возможное значение $y_i$:\n",
    "\n",
    "$\\large {\\sf P}(\\xi=y_i)= {\\sf P}(\\{\\omega_j : \\xi(\\omega_j)=y_i\\})$\n",
    "\n",
    "Распределение может быть как задано по условию задачи, так и являться искомым в задаче.\n",
    "\n",
    "**Пример.** Пусть $\\xi$ на пространстве графов — случайная величина, равная числу треугольников в графе. \n",
    "\n",
    "$\\large {\\sf P}(\\xi=k) = ?$\n",
    "\n",
    "Какое значение $k$ может принимать случайная величина, где $k$ представляет собой число треугольников в случайном графе на $n$ вершинах. Если граф был построен на $n$ вершинах, то максимальное число треугольников $C_n^3$ будет наблюдаться в случае полного графа. Значит, $k$ изменяется от $0$ до $C_n^3$:\n",
    "\n",
    "$\\large k=0,1,\\ldots,C_{n}^3$\n",
    "\n",
    "Тогда говорят, что известно распределение случайной величины $\\xi$, если известны следующие вероятности:\n",
    "\n",
    "$\\large {\\sf P}(\\xi=k), \\quad k=0,1,\\ldots,C_{n}^3$\n",
    "\n",
    "Вычислить точно распределение функции $\\xi$ с помощью численного расчета очень сложно, поэтому очень важны асимптотические методы оценки функций распределений случайных величин."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:black\" align=\"center\">Математическое ожидание случайной величины</h1>\n",
    "\n",
    "<h1 style=\"color:#008B8B\">Определение математического ожидания случайной величины</h1>\n",
    "\n",
    "**Математическое ожидание:**\n",
    "\n",
    "Математическое ожидание случайной величины $\\xi$ принято обозначать двумя различными способами. \n",
    "\n",
    "Обозначение $E\\xi$ восходит к английскому выражению \"expected value\", а $M\\xi$ — \"mean value\".\n",
    "\n",
    "Математическое ожидание случайной величины $\\xi$, определенной на конечном вероятностном пространстве, определяется согласно следующему выражению:\n",
    "\n",
    "$\\large M\\xi= \\sum\\limits_{\\omega\\in\\Omega} \\xi(\\omega)\\cdot {\\sf P}(\\omega)$\n",
    "\n",
    "В случае классической вероятностной схемы математическое ожидание соответствует среднему арифметическому последовательности из значений случайной величины. \n",
    "\n",
    "Почему математическое ожидание является средним значением? Если мы работаем с классической вероятностью, то веротяность $\\omega = \\frac{1}{n}$. Тогда, после всей суммы $\\omega$ по пространству элементарных исходов мы получим среднее арифметическое значение случайной величины.\n",
    "\n",
    "Вообще говоря, в любом случае математическое ожидание — это некое среднее значение (своего рода центр масс как в физике), так как  $\\sum\\limits_{\\omega\\in\\Omega}{\\sf P}(\\omega)=1$. Важно, что математическое ожидание может не принадлежать множеству возможных значений случайной величины."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Другая форма записи математического ожидания**\n",
    "\n",
    "Поскольку $\\xi$ на пространстве элементарных исходов принимает $k$ различных значений ($\\xi:\\Omega \\longrightarrow \\{y_1,\\ldots,y_k\\}$), тогда для разных элементарных исходов $\\omega$ из множества $\\Omega$ (пространства элементарных исходов), $\\xi(\\omega)$ может равнятся одному и тому же числу. Например, $y_1$ может приниматься на нескольких элементарных исходах $\\xi(\\omega)$.\n",
    "Поскольку несколько элементарных исходов могут давать одно и то же значение случайной величины, это определение можно переписать, сгруппировав такие элементарные исходы:\n",
    "\n",
    "Сначала собираем все $\\xi(\\omega)$, которые равняются $y_1$, это можно сделать следующим образом:\n",
    "\n",
    "$\\large y_1\\left(\\sum\\limits_{\\omega:\\xi(\\omega)=y_1}P(\\omega)\\right)$\n",
    "\n",
    "Запишем для всех $y_i$:\n",
    "\n",
    "$\\large M\\xi=\\sum\\limits_{\\omega\\in\\Omega}\\xi(\\omega)\\cdot P(\\omega)=y_1\\left(\\sum\\limits_{\\omega:\\xi(\\omega)=y_1}P(\\omega)\\right)+y_2\\left(\\sum\\limits_{\\omega:\\xi(\\omega)=y_2}P(\\omega)\\right)+\\ldots+y_k\\left(\\sum\\limits_{\\omega:\\xi(\\omega)=y_k}P(\\omega)\\right) =$\n",
    "\n",
    "Ну как у нас определялась вероятность события? Вероятность события – это сумма по всем элементарным исходам, которые этому событию благоприятствуют, вероятностей этих элементарных исходов. То есть, конечно же, написано так:\n",
    "\n",
    "$\\large = y_1 P(\\xi=y_1)+y_2 P(\\xi=y_2)+\\ldots +y_k P(\\xi=y_k)=\\sum\\limits_{j=1}^k y_j P(\\xi=y_j)$\n",
    "\n",
    "Последняя формула является естественным проявлением того факта, что математическое ожидание можно вычислить исходя из знания распределения случайной величины.\n",
    "\n",
    "**Замечание.** Однако часто бывает наоборот: математическое ожидание считается легче, чем распределение, и дает возможность получить некоторые важные свойства этого распределения, не вычисляя его."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#008B8B\">Свойство линейности математического ожидания, примеры</h1>\n",
    "\n",
    "Математическое ожидание обладает свойством линейности: пусть $\\xi_{1},\\xi_{2}$  — две произвольные случайные величины на конечном вероятностном пространстве, а $c_{1},c_{2}$ — произвольные вещественные числа, тогда\n",
    "\n",
    "$\\large M(c_1\\xi_1 +c_2\\xi_2)= c_1 M\\xi_1 + c_2 M\\xi_2$\n",
    "\n",
    "Это свойство непосредственно следует из определения математического ожидания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пример 1.** Найти математическое ожидание случайной величины $\\xi$, где $\\xi$ равна числу треугольников в случайном графе. Множество значений, которые принимает число треугольников в случайном графе — это множество чисел от $0$ до $C_n^3$. Ну тогда, естественно, надо каждое из этих значений умножить на вероятность того, что $\\xi = k$ и просуммировать пока от нуля до $C_n^3$: \n",
    "\n",
    "$\\large M\\xi=\\sum\\limits_{k=0}^{C_n^3} k\\cdot {\\sf P}(\\xi=k)$\n",
    "\n",
    "Чтобы решить данную задачу, необходимо обойти вычисление величины ${\\sf P}(\\xi=k)$ с помощью свойства линейности математического ожидания. Действительно:\n",
    "\n",
    "На вход случайной величины поступает случайный граф $\\large \\xi(G)$. И как на посчитать количество треугольников в графе? Самое простое, что можно сделать - это перебрать всевозможные тройки вершин, и для каждой тройки посмотреть, вот в этом конкретном графе, эта тройка вершин образует треугольник или нет? Ну если образует, добавить к счетчику $1$, если не образует, тогда ничего не добавлять. То есть, запись примет следующий вид:\n",
    "\n",
    "$\\large \\xi(G) = \\xi_1(G)+\\ldots+\\xi_{c_n^3}(G)$,\n",
    "\n",
    "где $\\xi_i(G)$ — случайная величина, которая равна $1$, если треугольник с номером $i$ принадлежит графу $G$. Другими словами, если $i$ тройка вершин образует треугольник в графе $G$, тогда $1$. Иначе, случайная величина равна нулю в иных случаях. Такие случайные величины называются индикаторами и записываются ещё в следующем виде:\n",
    "\n",
    "$\\large \\begin{equation*}\n",
    "\\xi_i(G) = \n",
    " \\begin{cases}\n",
    "   1, & \\text{если $i$ тройка вершин образует треугольник в графе $G$}\\\\\n",
    "   0 &\\text{иначе}\n",
    " \\end{cases}\n",
    "\\end{equation*}$\n",
    "\n",
    "Дальше, пользуемся свойством линейности и получаем, что математическое ожидание кси равно:\n",
    "\n",
    "$\\large M\\xi = M\\xi_1 +\\ldots+M\\xi_{c_n^3}$\n",
    "\n",
    "А математическое ожидание каждой из случайных величин $\\xi_i$ можно посчитать по следующей формуле:\n",
    "\n",
    "$\\large M\\xi_i= {\\sf P}(\\xi_i = 1)= p^3$\n",
    "\n",
    "Ну в самом деле, какие значения  $\\xi_i$ принимает? Это $1$ и $0$ То есть надо $1$ умножить на вероятность $1$ и прибавить $0$, умноженный на вероятность $0$. Так как ноль не вносит вклад, мы считаем, что математическое ожидание $\\xi_i$ равно вероятности того, что $\\xi_i = 1$. С какой вероятностью эта конкретная тройка вершин образует треугольник в случайном графе? Но каждое ребро возникает с вероятностью $p$, независимо от остальных. Значит все три вероятности $p$ необходимо перемножить и мы получаем $p^3$.\n",
    "\n",
    "У нас получилось, что каждая из вот этих слагаемых есть $p$ в кубе. Слагаемых $C_n^3$, ну в итоге получаем ответ $C_n^3$ на $p$ в кубе:\n",
    "\n",
    "$\\large M\\xi = M\\xi_1 +\\ldots+M\\xi_{c_n^3} = C_n^3 p^3$\n",
    "\n",
    "Воспользовавшись перегруппировкой слагаемых с помощью линейности можно найти ответ  практически в уме. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
